{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import platform as plat\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras as kr\n",
    "import numpy as np\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten\n",
    "from keras.layers import Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D,GRU, Bidirectional #, Merge\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adadelta, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechRecognitionModel():\n",
    "    '''\n",
    "    定义CNN/LSTM/CTC模型，使用函数式模型\n",
    "    输入层：200维的特征值序列，一条语音数据的最大长度设为1600（大约16s）\n",
    "    隐藏层：卷积池化层，卷积核大小为3x3，池化窗口大小为2\n",
    "    隐藏层：全连接层\n",
    "    输出层：全连接层，神经元数量为self.MS_OUTPUT_SIZE，使用softmax作为激活函数，\n",
    "    CTC层：使用CTC的loss作为损失函数，实现连接性时序多输出\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化\n",
    "        默认输出的拼音的表示大小是1423，即1423个拼音+1个空白块\n",
    "        '''\n",
    "        self.MS_OUTPUT_SIZE = 1423 + 1 # 神经网络最终输出的每一个字符向量维度的大小\n",
    "        #self.BATCH_SIZE = BATCH_SIZE # 一次训练的batch\n",
    "        self.label_max_string_length = 64\n",
    "        self.AUDIO_LENGTH = 1600\n",
    "        self.AUDIO_FEATURE_LENGTH = 200\n",
    "        \n",
    "        self.model, self.ctc_model = self._model_init()\n",
    "#         self.datapath = datapath\n",
    "#         self.slash = ''\n",
    "#         system_type = plat.system() # 由于不同的系统的文件路径表示不一样，需要进行判断\n",
    "#         if(system_type == 'Windows'):\n",
    "#             self.slash='\\\\' # 反斜杠\n",
    "#         elif(system_type == 'Linux'):\n",
    "#             self.slash='/' # 正斜杠\n",
    "#         else:\n",
    "#             print('*[Message] Unknown System\\n')\n",
    "#             self.slash='/' # 正斜杠\n",
    "#         if(self.slash != self.datapath[-1]): # 在目录路径末尾增加斜杠\n",
    "#             self.datapath = self.datapath + self.slash\n",
    "    \n",
    "    def _model_init(self):\n",
    "        input_data = Input(name=\"the_inputs\", shape=(None, self.AUDIO_FEATURE_LENGTH, 1))  \n",
    "        \n",
    "        x = Conv2D(32, (3,3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(input_data)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(32, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=None, padding='valid')(x)\n",
    "        \n",
    "        x = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=None, padding='valid')(x)\n",
    "        \n",
    "        x = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3,3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=None, padding='valid')(x)\n",
    "        \n",
    "        # 200 / 8 * 128 = 3200\n",
    "        x = Reshape(target_shape=(-1, 3200))(x)\n",
    "        \n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Dense(128, activation='relu', use_bias=True, kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        gru_units = 128\n",
    "        # 创建一个双向GRU，看看是否能增加精度？\n",
    "#         gru_1a = GRU(gru_units, return_sequences=True, kernel_initializer='he_normal', name='gru_1a')(x)\n",
    "#         gru_1b = GRU(gru_units, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru_1b')(x)\n",
    "        x = Bidirectional(GRU(gru_units, return_sequences=True, kernel_initializer='he_normal', name='gru_1'))(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Bidirectional(GRU(gru_units, return_sequences=True, kernel_initializer='he_normal', name='gru_2'))(x) \n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Dense(128, activation='relu', use_bias=True, kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        x = Dense(self.MS_OUTPUT_SIZE, use_bias=True, kernel_initializer='he_normal')(x)\n",
    "        \n",
    "        y_pred = Activation('softmax', name='y_pred_activation')(x)\n",
    "        model_data = Model(inputs=input_data, outputs=y_pred)\n",
    "        \n",
    "        labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "        input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "        loss_out = Lambda(self._ctc_batch_cost_func, output_shape=(1,), name='ctc_loss')([y_pred, labels, input_length, label_length])\n",
    "        \n",
    "        ctc_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "        ctc_model.summary()\n",
    "        \n",
    "        optimizer = Adam(learning_rate=0.0003, beta_1=0.9, beta_2=0.999, decay=0.0, epsilon=10e-8)\n",
    "        ctc_model.compile(optimizer=optimizer, loss={'ctc_loss': lambda y_true, y_pred: y_pred}, metrics=['acc'])\n",
    "        \n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "#         test_func = K.function([input_data], [self.y_pred])\n",
    "#         pdb.set_trace()\n",
    "\n",
    "        #print('[*提示] 创建模型成功，模型编译成功')\n",
    "        print('[*Info] Create Model Successful, Compiles Model Successful. ')\n",
    "        return model_data, ctc_model\n",
    "        \n",
    "        \n",
    "    def _ctc_batch_cost_func(self, args):\n",
    "        y_pred, labels, input_length, label_length = args\n",
    "\n",
    "#         pdb.set_trace()\n",
    "        y_pred = y_pred[:, :, :]\n",
    "        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# with tf.Session() as s:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ctc': <function __main__.<lambda>(y_true, y_pred)>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from speech_data import *\n",
    "\n",
    "wav_list = get_thchs30_data(wav_base_path=\"H:\\\\PycharmProjects\\\\dataset\\\\data_thchs30\\\\train-test\")\n",
    "batch = data_generator(wav_list, batch_size)\n",
    "y_pred = next(batch)[0]['the_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: Tensor(\"y_pred_activation_11/truediv:0\", shape=(?, ?, 1424), dtype=float32)\n",
      "labels Tensor(\"the_labels_11:0\", shape=(?, ?), dtype=float32)\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_inputs (InputLayer)         (None, None, 200, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, 200, 32 288         the_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, None, 200, 32 128         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, 200, 32 9248        batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, None, 200, 32 128         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling2D) (None, None, 100, 32 0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, 100, 64 18496       max_pooling2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, None, 100, 64 256         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, 100, 64 36928       batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, None, 100, 64 256         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, 100, 64 36928       batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, None, 100, 64 256         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, 100, 64 36928       batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, None, 100, 64 256         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D) (None, None, 50, 64) 0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, 50, 128 73856       max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, None, 50, 128 512         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, 50, 128 147584      batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, None, 50, 128 512         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, 50, 128 147584      batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, None, 50, 128 512         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, 50, 128 147584      batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, None, 50, 128 512         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, None, 50, 128 147584      batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, None, 50, 128 512         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, None, 50, 128 147584      batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, None, 50, 128 512         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling2D) (None, None, 25, 128 0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)            (None, None, 3200)   0           max_pooling2d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, 3200)   0           reshape_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, None, 128)    409728      dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, None, 128)    512         dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, None, 256)    197376      batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, None, 256)    1024        bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_24 (Bidirectional (None, None, 256)    295680      batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, None, 256)    1024        bidirectional_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, None, 128)    32896       batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, None, 128)    512         dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, None, 1424)   183696      batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "y_pred_activation (Activation)  (None, None, 1424)   0           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss (Lambda)               (None, 1)            0           y_pred_activation[0][0]          \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,077,392\n",
      "Trainable params: 2,073,680\n",
      "Non-trainable params: 3,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*Info] Create Model Successful, Compiles Model Successful. \n",
      "Epoch 1/8\n",
      " 891/2500 [=========>....................] - ETA: 13:13 - loss: 247.8625 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "from speech_data import *\n",
    "\n",
    "model = SpeechRecognitionModel()\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 4\n",
    "\n",
    "train_wav_list = get_thchs30_data(wav_base_path=\"H:\\\\PycharmProjects\\\\dataset\\\\data_thchs30\\\\train\")\n",
    "validation_wav_list = get_thchs30_data(wav_base_path=\"H:\\\\PycharmProjects\\\\dataset\\\\data_thchs30\\\\dev\")\n",
    "batch_num = len(train_wav_list) // batch_size\n",
    "val_batch_num = len(validation_wav_list) // batch_size\n",
    "\n",
    "train_batch = data_generator(train_wav_list, batch_size)\n",
    "validation_batch = data_generator(validation_wav_list, batch_size)\n",
    "\n",
    "history = model.ctc_model.fit_generator(train_batch,\n",
    "                                        steps_per_epoch=batch_num,\n",
    "                                        epochs=8\n",
    "                                       )\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     print(\"Begin epoch:\", i+1)\n",
    "#     train_batch = data_generator(train_wav_list, batch_size)\n",
    "#     history = model.ctc_model.fit_generator(train_batch, steps_per_epoch=batch_num, epochs=1)\n",
    "#     print(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
