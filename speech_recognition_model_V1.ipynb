{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\AnaConda\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import platform as plat\n",
    "import os\n",
    "import time\n",
    "\n",
    "import keras as kr\n",
    "import numpy as np\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Reshape, BatchNormalization # , Flatten\n",
    "from keras.layers import Lambda, TimeDistributed, Activation,Conv2D, MaxPooling2D,GRU, Bidirectional #, Merge\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adadelta, Adam\n",
    "\n",
    "# 指定第一块GPU可用\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.common import *\n",
    "from utils.wav_preprocess import compute_freq_feature\n",
    "from speech_data import test_data_generator\n",
    "\n",
    "py2id_dict = pinyin2id()\n",
    "id2py_dict = dict(zip(py2id_dict.values(), py2id_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LOGS_DIR_NAME = \"logs_speechRec_1\"\n",
    "\n",
    "class SpeechRecognitionModelV1():\n",
    "    '''\n",
    "    定义CNN/LSTM/CTC模型，使用函数式模型\n",
    "    输入层：200维的特征值序列，一条语音数据的最大长度设为1600（大约16s）\n",
    "    隐藏层：卷积池化层，卷积核大小为3x3，池化窗口大小为2\n",
    "    隐藏层：全连接层\n",
    "    输出层：全连接层，神经元数量为self.MS_OUTPUT_SIZE，使用softmax作为激活函数，\n",
    "    CTC层：使用CTC的loss作为损失函数，实现连接性时序多输出\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化\n",
    "        默认输出的拼音的表示大小是1423，即1423个拼音+1个空白块\n",
    "        '''\n",
    "        self.MS_OUTPUT_SIZE = 1422 + 1 + 1  # 神经网络最终输出的每一个字符向量维度的大小\n",
    "        # self.BATCH_SIZE = BATCH_SIZE # 一次训练的batch\n",
    "        self.label_max_string_length = 64\n",
    "        self.AUDIO_LENGTH = 16000\n",
    "        self.AUDIO_FEATURE_LENGTH = 200\n",
    "\n",
    "        self.model, self.ctc_model = self._model_init()\n",
    "\n",
    "    def _model_init(self):\n",
    "        input_data = Input(name=\"the_inputs\", shape=(None, self.AUDIO_FEATURE_LENGTH, 1))\n",
    "\n",
    "        x = Conv2D(32, (3, 3), use_bias=False, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "            input_data)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(32, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=None, padding='valid')(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=None, padding='valid')(x)\n",
    "\n",
    "        x = Conv2D(128, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(128, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Conv2D(128, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3, 3), use_bias=True, activation='relu', padding='same', kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=None, padding='valid')(x)\n",
    "\n",
    "        # 200 / 8 * 128 = 3200\n",
    "        # 因为DFT抽样点数必须为2的整数次幂，经过3层maxpooling层，要求音频数据的每个维度需要能够被8整除\n",
    "        x = Reshape(target_shape=(-1, 3200))(x)\n",
    "\n",
    "        # x = Dropout(0.2)(x)\n",
    "        x = Dense(128, activation='relu', use_bias=True, kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        gru_units = 128\n",
    "        # 创建一个双向GRU，看看是否能增加精度？\n",
    "        #         gru_1a = GRU(gru_units, return_sequences=True, kernel_initializer='he_normal', name='gru_1a')(x)\n",
    "        #         gru_1b = GRU(gru_units, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru_1b')(x)\n",
    "        x = Bidirectional(GRU(gru_units, return_sequences=True, kernel_initializer='he_normal', name='gru_1'))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Bidirectional(GRU(gru_units, return_sequences=True, kernel_initializer='he_normal', name='gru_2'))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Dense(128, activation='relu', use_bias=True, kernel_initializer='he_normal')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Dense(self.MS_OUTPUT_SIZE, use_bias=True, kernel_initializer='he_normal')(x)\n",
    "\n",
    "        y_pred = Activation('softmax', name='y_pred_activation')(x)\n",
    "        model_data = Model(inputs=input_data, outputs=y_pred)\n",
    "\n",
    "        labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "        input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "        label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "        loss_out = Lambda(self._ctc_batch_cost_func, output_shape=(1,), name='ctc_loss')(\n",
    "            [y_pred, labels, input_length, label_length])\n",
    "\n",
    "        ctc_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "        ctc_model.summary()\n",
    "\n",
    "        optimizer = Adam(learning_rate=0.0003, beta_1=0.9, beta_2=0.999, decay=0.0, epsilon=10e-8)\n",
    "        ctc_model.compile(optimizer=optimizer, loss={'ctc_loss': lambda y_true, y_pred: y_pred}, metrics=['acc'])\n",
    "\n",
    "        # captures output of softmax so we can decode the output during visualization\n",
    "        #         test_func = K.function([input_data], [self.y_pred])\n",
    "        #         pdb.set_trace()\n",
    "\n",
    "        # print('[*提示] 创建模型成功，模型编译成功')\n",
    "        print('[*Info] Create Model Successful, Compiles Model Successful. ')\n",
    "        return model_data, ctc_model\n",
    "\n",
    "    def _ctc_batch_cost_func(self, args):\n",
    "        y_pred, labels, input_length, label_length = args\n",
    "\n",
    "        #         pdb.set_trace()\n",
    "        y_pred = y_pred[:, :, :]\n",
    "        return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "    def predict(self, data_input, input_len):\n",
    "        '''\n",
    "        预测结果，返回拼音对应的id列表\n",
    "        :param data_input: 输入的音频数据\n",
    "        :param input_len: 音频的长度\n",
    "        :return:\n",
    "        '''\n",
    "        batch_size = 1\n",
    "\n",
    "        base_pred = self.model.predict(data_input, batch_size)\n",
    "#         print(\"base_pred-pre:\", base_pred)\n",
    "        base_pred = base_pred[:, :, :]\n",
    "#         print(\"base_pred:\", base_pred)\n",
    "\n",
    "        r = K.ctc_decode(base_pred, input_len, greedy=True, beam_width=100, top_paths=1)\n",
    "#         print(\"r:\", r)\n",
    "        r1 = K.get_value(r[0][0])\n",
    "#         print(\"r1:\", r1)\n",
    "\n",
    "        return r1\n",
    "\n",
    "    def recognize(self, wav_file):\n",
    "        '''\n",
    "        wav 文件识别出拼音\n",
    "        :param wav_file:\n",
    "        :return:\n",
    "        '''\n",
    "        data_input = compute_freq_feature(wav_file)\n",
    "        input_length = len(data_input) // 8\n",
    "\n",
    "        data_input = np.array(data_input, dtype=np.float)\n",
    "        data_input = np.reshape(data_input.shape[0], data_input.shape[1], 1)\n",
    "\n",
    "        r1 = self.predict(data_input, input_length)\n",
    "        recognize_pingyin_list = [id2py_dict[id] for id in r1]\n",
    "        return recognize_pingyin_list\n",
    "\n",
    "    def test_model(self, wav_label_list, data_batch_size=4):\n",
    "        '''\n",
    "        验证模型的水准\n",
    "        :param wav_data_path:  验证集wav数据集合\n",
    "        :param labels_data_path: 对应的拼音labels id集合\n",
    "        :param data_batch_size: 验证集的数量\n",
    "        :return:\n",
    "        '''\n",
    "\n",
    "        for next_index in range(data_batch_size):\n",
    "            batch = data_generator(wav_label_list, 1)\n",
    "\n",
    "            word_error_num = 0\n",
    "            word_total_num = 0\n",
    "            input, output = next(batch)\n",
    "\n",
    "            y_predict = self.predict(input, input['input_length'])\n",
    "            label = input['the_labels']\n",
    "\n",
    "            real_str = ''.join([id2py_dict[id] for id in label[0].tolist()])\n",
    "            predict_str = ''.join([id2py_dict[id] for id in y_predict[0].tolist()])\n",
    "\n",
    "            words_num = label.shape[1]\n",
    "            word_total_num += words_num\n",
    "            distance = calculate_sequence_edit_distance(label[0].tolist(), y_predict[0].tolist())\n",
    "            if distance <= words_num:\n",
    "                word_error_num += distance  # 使用编辑距离作为错误字数\n",
    "            else:  # 否则肯定是增加了一堆乱七八糟的奇奇怪怪的字,就直接加句子本来的总字数就好了\n",
    "                word_error_num += words_num\n",
    "\n",
    "            print(\"[原本语音内容]：\", real_str)\n",
    "            print('[**预测结果**]：', predict_str)\n",
    "            print(\"============********============\" + \"\\n\")\n",
    "\n",
    "        acc = (word_total_num - word_error_num) / word_total_num\n",
    "        print('*本轮语音测试准确率：', str(acc))\n",
    "\n",
    "    def load_last_weights(self):\n",
    "        sorted_model_list = sorted(glob.glob(os.path.join(MODEL_LOGS_DIR_NAME, '*.model')),\n",
    "                                   key=lambda x: time.localtime(os.path.getmtime(x)),\n",
    "                                   reverse=True)\n",
    "        if len(sorted_model_list) == 0:\n",
    "            return\n",
    "        sorted_ctc_model_list = sorted(glob.glob(os.path.join(MODEL_LOGS_DIR_NAME, '*.model.base')),\n",
    "                                       key=lambda x: time.localtime(os.path.getmtime(x)),\n",
    "                                       reverse=True)\n",
    "\n",
    "        self.model.load_weights(sorted_model_list[0])\n",
    "        self.ctc_model.load_weights(sorted_ctc_model_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_various_wav_train_data start, please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "421it [06:32,  1.07it/s]\n",
      "341it [04:49,  1.18it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_various_wav_train_data has ended...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [01:07,  1.11s/it]\n",
      "41it [00:35,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from utils.wav_preprocess import *\n",
    "\n",
    "train_wav_list = load_various_wav_train_data()\n",
    "validation_wav_list = load_various_wav_dev_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_inputs (InputLayer)         (None, None, 200, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, 200, 32 288         the_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 200, 32 128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, 200, 32 9248        batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 200, 32 128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, None, 100, 32 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, 100, 64 18496       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 100, 64 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, 100, 64 36928       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 100, 64 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, 100, 64 36928       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, 100, 64 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, 100, 64 36928       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, 100, 64 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, None, 50, 64) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, 50, 128 73856       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, 50, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, 50, 128 147584      batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, 50, 128 512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, 50, 128 147584      batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, 50, 128 512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, 50, 128 147584      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, 50, 128 512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, 50, 128 147584      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, None, 50, 128 512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, 50, 128 147584      batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, None, 50, 128 512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, None, 25, 128 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, None, 3200)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, None, 128)    409728      reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, None, 128)    512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 256)    197376      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, None, 256)    1024        bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, None, 256)    295680      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, 256)    1024        bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, 128)    32896       batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, 128)    512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, None, 1424)   183696      batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "y_pred_activation (Activation)  (None, None, 1424)   0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss (Lambda)               (None, 1)            0           y_pred_activation[0][0]          \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,077,392\n",
      "Trainable params: 2,073,680\n",
      "Non-trainable params: 3,712\n",
      "__________________________________________________________________________________________________\n",
      "[*Info] Create Model Successful, Compiles Model Successful. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin epoch: 1\n",
      "Epoch 1/1\n",
      "40000/40000 [==============================] - 11116s 278ms/step - loss: 2.1392 - acc: 0.3977\n",
      "[原本语音内容]： wo3xiang1xin4wo3li2jin1yao1dai4de5ju4li2yue4lai2yue4jin4\n",
      "[**预测结果**]： wo3xiang1xin4wo3li2jin1yao4dai4de5ju4li2yue4lai2yue4jin4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zeng1fu2da2dao4bai3fen1zhi1yi1\n",
      "[**预测结果**]： zeng1fu2da2dao4bai3fen1zhi1yi1\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： dan4zai4bi3sai4de5di4dian3ji2shi2jian1shang4hai2zai4jin4yi2bu4shang1liang2\n",
      "[**预测结果**]： da4zai4bi3sai4de5di4dian3ji2shi2dian4shang4hai2dai4jin4yi2bu4sheng4liang4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： qie3fu1nu2nu2a1wen2que4shang4wu2tou1wen2ru2ou1yang2gong1zhi1e4de2er2wen2zhang1yi4jiao4wei2neng2zuo4zuo5zhe3ye3\n",
      "[**预测结果**]： qi2fu1nu2nu2a1wen2que4shang4wu2tou2wen2ru2ou1yang2gong1zhi1e4de2er2wen2zhang1yi4jiao3wei2neng2zuo4zuo5zhe5ye3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： shou3shi4nv3ren2de5di4er4zhang1lian3\n",
      "[**预测结果**]： shou3shi2nv3ren2de5di4er4zhan4li3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： yi1ba1qi1er4er4liu4ba1jiu3wu3\n",
      "[**预测结果**]： yi1ba1qi1er4er4liu4ba1jiu3wu3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： deng3hui4er5wo3gei3ni3da3dian4hua4\n",
      "[**预测结果**]： deng3hui4wo3gei3ni3da3dian4hua4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： na4ke3shi4wo3de5yi1ke1zhen1xin1\n",
      "[**预测结果**]： la1ke4shuo1wo3de5yi1ke1zhen1xin1\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： jin3zai4er4ling2yi1si4nian2di4si4nian2ji4du4\n",
      "[**预测结果**]： jin3dan4er4ling2yi1si4nian2di4si4nian2ji1du4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： guo2ji4guo2nei4da4dou4you2yuan2liao4shi4chang3cheng2xian4jia4ge2chi2xu4zou3gao1de5qu1shi4\n",
      "[**预测结果**]： guo2ji4guo2nei4da4dou4you2yuan2liao4shi4chang3cheng2xian4jia4ge2chi2xu4jiu3gao1de5qu1shi4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： qie3gai1wen4ti2duan3shi2jian1nei4bu4neng2hui1fu4\n",
      "[**预测结果**]： qie3gai1wen4ti2duan3shi2jian1nei4bu4neng2hui1fu4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： bu4ke3neng2wo3gen1ta1shi4bu4ke3neng2de5la5\n",
      "[**预测结果**]： bu4ke3neng2wo3gen1ta1shi4bu4ke3neng2na4le5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zheng3ge4zhe4ge4xuan3ba2sai4ye3shi4shou4zhe4ge4ying3xiang3bi3jiao4da4\n",
      "[**预测结果**]： zheng3ge4zhe4ge4xuan3ba2se4ye3shi4shou4zhe4ge4ying3xiang3bi3jiao4da4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： hen3duo1di4fang1dou1mei2you3tiao2zheng3xue4tou4de5jian3cha2fei4yong4\n",
      "[**预测结果**]： hen3duo1di4fang1dou1mei2you3tiao2zheng3que4tou4de5jian3cha2fei4yong4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： qing2xu4bi3jiao4shi4ran2zui4hou4yi1ci4\n",
      "[**预测结果**]： qing2xu4bi3jiao4shi4ran2zui4hou4yi1ci4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zhang1jia1kou3de5fang2di4chan3shi4chang3zai4er4ling2yi1er4nian2hou4yi4zhi2chu3yu2di1mi2shi2qi1\n",
      "[**预测结果**]： zhang1jia1kou3de5fang2di4chan3shi4chang3zai4er4ling2yi1er4nian2hou4yi4zhi2chu3yu2di1mi2zhi2qi1\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wo3dao4le5gei3ni3fa1dian4hua4\n",
      "[**预测结果**]： wo3dao4le5gei3ni3fa1zui4hua4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： ming2tian1de5tian1qi4shi4zen3me5yang4de5\n",
      "[**预测结果**]： ming2tian1de5tian1qi4shi4zen3me5yang4de5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： han4yi4ying1cong1ming2de5rui4zhi4de5\n",
      "[**预测结果**]： han4yi4ying1cong1ming2de5rui4zhi4de5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： hua4shuo1ni3zen3me5hai2mei2shui4\n",
      "[**预测结果**]： hua4shuo1ni3zen3me5hai2mei2shui4er2\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： dui4zhang3hui4ruo4qi2xin1zang4chu1xian4wen4ti2\n",
      "[**预测结果**]： dui4zhang3hui4luo4qi4xin1zang4chu1xian4wen4ti2\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wo3yao4qu4da3ma2jiang1lao3po2bu4gei3\n",
      "[**预测结果**]： wo3yao4qu4da3ma2jiang1lao3po2bu4gei3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wo3men5xing1qi1liu4yao4shang4ke4\n",
      "[**预测结果**]： huo3men5xing1qi1liu4yao1shang4ke4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zai4ya4jin3sai4nan2dan1ba1fen1zhi1yi1jue2sai4zhong1\n",
      "[**预测结果**]： zai4ya4jin3sai4nan2dan1ba1fen1zhi1yi1jue2sai4zhong1\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： lv3you2ju2che4xiao1dui4wu3tai2shan1jing3gao4chu3fen4wang2ru2lin2ceng2pi1dang1di4gan4bu4\n",
      "[**预测结果**]： lv3you2ju2te4xiang1dui4wu3tai2shan1jing3gao4chu4fen4wang2lin2cheng2pin1dang1di4gan4bu2\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： yi3hou4bu4gei3ni3kai1wan2xiao4le5\n",
      "[**预测结果**]： yi3hou4bu4gei3ni3kai1le5xiao3le5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： dan4shi4ta1ning4yuan4rang4zi4ji3he2qi1zi5er2nv3chi1kang1yan4cai4ye3bu2rang4wang2shi4yun2lao3ren2chi1ku3\n",
      "[**预测结果**]： dan4shi4ta1ning4yuan4rang4zi4ji3he2qi1zi3er2yu3chi1kang1yan4cai4ye3bu2rang4wang2shi4yun2lao3ren2chi1ku3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： tian1qi4leng3le5duo1chuan1yi1fu5\n",
      "[**预测结果**]： tian1qi4leng3le5duo1chuan1yi1fu5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： dian3ji1jin4ru4gu3you3hui4can1yu4tao3lun4\n",
      "[**预测结果**]： dian3ji1jin4ru4gu3you3hui4can1yu4tao3lun4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： shi4chang3kai1shi3qi3dong4bing4xun4su4fa1zhan3\n",
      "[**预测结果**]： shi4chang3kai1shi3qi3dong4bing4xun4su4fa1jia4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wan3an1\n",
      "[**预测结果**]： wan3an1\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： mou3di4xin1kai1fa1chu1yi1ge4shan1shui3jing3dian3\n",
      "[**预测结果**]： mou3di4xin1kai1fa1chu1yi2ge4shen1shui4jing3dian3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： ni3de5yan3jing1da4bu4da4\n",
      "[**预测结果**]： ni3de5yan3jing1da4bu4dao4a5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wo3xiang3ting1zheng4zhi4hua4de5shui3shou3\n",
      "[**预测结果**]： wo3xiang3ting1zheng4zhi4hua4de5shui3shen3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： da3dian4hua4gei3chen2yi1hua2\n",
      "[**预测结果**]： da3dian4hua4gei3chen2li3yi1hua4a5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： xian4zai4de5fang2jia4duo1shao3qian2yi1ping2mi3ya5\n",
      "[**预测结果**]： xian4zai4de5fang2jia4duo1shao3qian2yi1ping2mi3ya5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zhe4ye3fu2he2shou3du1fa1zhan3gong1neng2zhuan3bian4de5qu1shi4\n",
      "[**预测结果**]： zhe4ye3fu2he2shou3du1fa1zhan3gong1neng2zhuan3mian4de5qu1shi4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： liang3jia1di4chan3zhong1jie4gong1si1men2shi4yuan2gong1wei4qiang3ke4yuan2da4da3chu1shou3\n",
      "[**预测结果**]： liang3jia1di4chan3zhong1jie4gong1si1men2shi4yuan2gong1wei4qiang3ke4yuan2da4da3chu1xiao3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： dan4shi4ye3shi4jiu3jing1sha1chang3ba5\n",
      "[**预测结果**]： dan4shi4ye3shi4jiu3jing1sha1chang3ba5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wo3ming2tian1wan3shang4jiu4zou3le5\n",
      "[**预测结果**]： wo3ming2tian1wan3shang4jiu4zao3le5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： kun1ming2nei3xie1xue2xiao4zhao1san1xue2sheng1\n",
      "[**预测结果**]： kun1ming2nei3xie1xue3xiao4shao1shang4xue2xiao4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： dan4dui4yu2yan3xia4chuang4ye4zhe3yun2yong3de5shi2qi1\n",
      "[**预测结果**]： dan4dui4yu2yan3xia4chuang4ye4zhe3yuan3yong3de5shi2qi1\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wan2shan4nong2cun1fa1zhan3ti3zhi4ji1zhi4\n",
      "[**预测结果**]： wan2shan4nong2cun1fa1zhan3ti3zhi4ji1zhi4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： ge2li4dian4qi4ci3ci4gong4fen1hong2pai4xian4chao1guo4jiu3shi2yi4yuan2\n",
      "[**预测结果**]： ge2li4dian4qi4ci3ci4gong4fang1hong2pai4xian4chao1guo4jiu3shi2yi4yuan2\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： chi1wan2fan4le5ma5qin1ai4de5\n",
      "[**预测结果**]： chi1wan2fan4le5ma5qin1ai4de5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： rang4che1shang4de5si4ming2cheng2ke4gan3kai3bu4yi3\n",
      "[**预测结果**]： rang4che1shang4de5si4ming2cheng2ke4gan3kai3bu4yi4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： chong1hao3dian4hou4jiao4xing3wo3\n",
      "[**预测结果**]： chuang2hao3dian4hou4jiao4xing3wo3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zen3me5yi2ge4ren2guo4zhou1mo4\n",
      "[**预测结果**]： zen3me5yi2ge4ren2guo4zhou1mo4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： tu1ran2hen3xiang3zhao3ren2shuo1shuo1hua4\n",
      "[**预测结果**]： tu1ran2hen3xiang3zhao3ren2shuo1shuo1hua4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： sou1hu2yu2le4xun4you2er4shi2shi4ji4fu2si1dian4ying3gong1si1chu1pin3\n",
      "[**预测结果**]： sou1hu2yu2le4xun4you2er4shi2shi4ji4fu2si1dian4ying3gong1si1chu1pin3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： ni3yi4ban1shen2me5shi2hou4you3kong4\n",
      "[**预测结果**]： ni3mai3shen2me5shi2hou4you3kong4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： tai2wan1zhen1xin1hua4da4mao4xian3\n",
      "[**预测结果**]： tai2wan1zhen1xin4hua4dan1bao1xian3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： yu3qu4nian2xiang1bi3jian3shao3si4wan4ping2mi3\n",
      "[**预测结果**]： yu3qu4nian2xiang1bi3jian3shao3si4wan4ping2mi3\n",
      "============********============\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原本语音内容]： dan4shi4pai1she4de5guo4cheng2que4shi4fei4le5bu4shao3li4qi4\n",
      "[**预测结果**]： dan4shi4pai1she4de5guo4cheng2que4shi2fei4le5bu4shao3li4qu3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： hai3dian4tai4ping2zhuang1di4kuai4ti3liang4bu4da4\n",
      "[**预测结果**]： hai3dian4tai4ping2zhuang1di4kuai4ti3liang4bu4da4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wo3yi2ge4ren2shui4jiao4hao3leng3\n",
      "[**预测结果**]： wo3yi2ge4ren2shui4jiao4hao3de5leng3\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zhi1chi2min2qi3rong2zi1kai1zhan3guo2ji4he2zuo4ju4ren4zhi4wu3jie4shao4\n",
      "[**预测结果**]： zhi1chi2min2qi3rong2zi1kai1zhan3guo2ji4he2zuo4ju4ren4zheng4jie4shang4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zhe4shi4ge4you3qian2jing3de5ling3yu4\n",
      "[**预测结果**]： zhe4shi4ge4you3qian2jing3de5ling3yu4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： jian3dan1sheng1huo2jie2hai2jiang1zai4wei4lai2gong1bu4shen2mi4jia1bin1\n",
      "[**预测结果**]： jian3dan1sheng1bo2jin3hai2jiang1zai4wei4lai2gong1bu4shen3mi4jia1bin1\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： wo3jiu4gen1ni3yi2ge4ren2liao2\n",
      "[**预测结果**]： wo3jiu4gen1ni3yi2ge4ren2liao2\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： ni3xiang3he2wo3yue1hui4ma5\n",
      "[**预测结果**]： ni3xiang3he2wo3yue1hui4ma5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： ni3shi4bu2shi4fa1sheng1shen2me5shi4le5\n",
      "[**预测结果**]： ni3shi4bu2shi4fa1shang1zen3me5chi1le5\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： chong2xin1guan1zhu4hui2zi4ji3de5jiao3bu4\n",
      "[**预测结果**]： chong2xin1guan1zhu4hui2zi4ji3de5jiao3gu4\n",
      "============********============\n",
      "\n",
      "[原本语音内容]： zhi3shi4yao4pin3ming2cheng1bu4yi2yang4de5gao1jia4yao4\n",
      "[**预测结果**]： zhi3shi4yao4pin3ming2cheng1bu4yi1yang4de5gao1jia4yao4\n",
      "============********============\n",
      "\n",
      "*本轮语音测试准确率： 0.9230769230769231\n",
      "Begin epoch: 2\n",
      "Epoch 1/1\n",
      " 3477/40000 [=>............................] - ETA: 2:48:31 - loss: 1.8859 - acc: 0.4352"
     ]
    }
   ],
   "source": [
    "from speech_data import *\n",
    "# from speechRecognitionModelV1 import SpeechRecognitionModelV1\n",
    "\n",
    "m = SpeechRecognitionModelV1()\n",
    "train_wav_list = train_wav_list[:240000]\n",
    "epochs = 100\n",
    "batch_size = 6\n",
    "\n",
    "batch_num = len(train_wav_list) // batch_size\n",
    "# val_batch_num = int(batch_num * 0.2)\n",
    "\n",
    "train_batch = data_generator(train_wav_list, batch_size)\n",
    "# validation_batch = data_generator(validation_wav_list, batch_size)\n",
    "\n",
    "m.load_last_weights()\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"Begin epoch:\", i+1)\n",
    "    train_batch = data_generator(train_wav_list, batch_size)\n",
    "    history = m.ctc_model.fit_generator(train_batch,\n",
    "                                        steps_per_epoch=batch_num,\n",
    "                                        epochs=1)\n",
    "    m.test_model(wav_label_list=validation_wav_list, data_batch_size=64)\n",
    "\n",
    "    m.model.save_weights(os.path.join(MODEL_LOGS_DIR_NAME, str(i) +'_steps_SpeechRecognitionModelV1.model'))\n",
    "    m.ctc_model.save_weights(os.path.join(MODEL_LOGS_DIR_NAME, str(i) +'_steps_SpeechRecognitionModelV1.model.base'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
